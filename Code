{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"8f14708d3b9444b38c6d7bc544a47382","deepnote_cell_type":"markdown"},"source":"# Homework due Oct 25, 2023, 11:59pm\n\nFirst, I'll load the dataset you'll be working with.  See further below for a description of this dataset and the specifics of your assignment.","block_group":"2332987ce62f4780ad61f416a125c86b"},{"cell_type":"markdown","metadata":{"cell_id":"438153b305ef4657a37c41ece48339e3","deepnote_cell_type":"markdown"},"source":"# Description of data source\n\nI got the data from Kaggle.com, and I include part of their description here.\n\n### Context\nThis is a dataset of data science job posts in glassdoor.\n\n### Content\nThe data was scraped from glassdoor's website. The columns have the following meanings.\n\n * Job Title: Title of the job posting\n * Salary Estimate: Salary range for that particular job\n * Job Description: This contains the full description of that job\n * Rating: Rating of the job post from which the row was scraped\n * Company: Name of company posting the job\n * Location: Location of the company\n * Headquarters: Location of the headquater\n * Size: Approximate number of employees in that company\n * Founded: Year the company was founded\n * Type of ownership: examples include non-profit, public, private firm, etc.\n * Industry, Sector: Field applicant will work in\n * Revenue: Total revenue of the company\n * Competitors: List of competitors for the company, if any were available in the job posting\n\n# Your task\n\n 1. Work in a duplicated copy of this project and edit this file by adding new code cells below.\n 2. Clean the data to make it more useful.\n 3. Document each step of your work so that I know why you made the decisions you did, and what your intentions were for each block of code.\n 4. As with the previous homework assignment, download the resulting `.ipynb` file and upload it to Brightspace.\n \nI am intentionally not telling you how to clean the data, because data cleaning is a process that starts with first noticing what's wrong, and coming up with creative ways to fix it when possible.\n\nNote that you can surely find this dataset online, and find other people who have written code to clean it.  But be warned!  They didn't always do a good job!  It will be a better learning experience (and probably produce a better result) if you clean the dataset on your own rather than looking up clues or hints that might actually lead you astray.\n\n# What may I use?\n\nYou can use anything we've learned in class, of course.  You may also use AI, and you can still get full credit by using code generated by AI, but please report that you did so just as you would cite any source.\n\n***You should not take code from any classmate, however, because that would not be doing your own work.***  Feel free to talk at a high level with classmates about the assignment, but you should write your own code, never copying someone else's.","block_group":"7858b0913dd84ed6b3f7f371dfd2ef2d"},{"cell_type":"code","metadata":{"source_hash":"906d5818","execution_start":1698280321851,"execution_millis":362,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":100,"pageIndex":6},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"9122b2608a9e4c42b750d7c73dd9d760","deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv( 'DS_jobs.csv' )\n\n# Display the first few rows to understand its structure and contents\ndf.head()","block_group":"8d69a6ffdc4c40088fc995d59cbb6018","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":15,"row_count":5,"columns":[{"name":"index","dtype":"int64","stats":{"unique_count":5,"nan_count":0,"min":"0","max":"4","histogram":[{"bin_start":0,"bin_end":0.4,"count":1},{"bin_start":0.4,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":1.2000000000000002,"count":1},{"bin_start":1.2000000000000002,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":2,"count":0},{"bin_start":2,"bin_end":2.4000000000000004,"count":1},{"bin_start":2.4000000000000004,"bin_end":2.8000000000000003,"count":0},{"bin_start":2.8000000000000003,"bin_end":3.2,"count":1},{"bin_start":3.2,"bin_end":3.6,"count":0},{"bin_start":3.6,"bin_end":4,"count":1}]}},{"name":"Job Title","dtype":"object","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"Data Scientist","count":4},{"name":"Sr Data Scientist","count":1}]}},{"name":"Salary Estimate","dtype":"object","stats":{"unique_count":1,"nan_count":0,"categories":[{"name":"$137K-$171K (Glassdoor est.)","count":5}]}},{"name":"Job Description","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"Description\n\nThe Senior Data Scientist is responsible for defining, building, and improving statistical models to improve business processes and outcomes in one or more healthcare domains such as Clinical, Enrollment, Claims, and Finance. As part of the broader analytics team, Data Scientist will gather and analyze data to solve and address complex business problems and evaluate scenarios to make predictions on future outcomes and work with the business to communicate and support decision-making. This position requires strong analytical skills and experience in analytic methods including multivariate regressions, hierarchical linear models, regression trees, clustering methods and other complex statistical techniques.\n\nDuties & Responsibilities:\n\n• Develops advanced statistical models to predict, quantify or forecast various operational and performance metrics in multiple healthcare domains\n• Investigates, recommends, and initiates acquisition of new data resources from internal and external sources\n• Works with multiple teams to support data collection, integration, and retention requirements based on business needs\n• Identifies critical and emerging technologies that will support and extend quantitative analytic capabilities\n• Collaborates with business subject matter experts to select relevant sources of information\n• Develops expertise with multiple machine learning algorithms and data science techniques, such as exploratory data analysis and predictive modeling, graph theory, recommender systems, text analytics and validation\n• Develops expertise with Healthfirst datasets, data repositories, and data movement processes\n• Assists on projects/requests and may lead specific tasks within the project scope\n• Prepares and manipulates data for use in development of statistical models\n• Other duties as assigned\n\nMinimum Qualifications:\n\n-Bachelor's Degree\n\nPreferred Qualifications:\n\n- Master’s degree in Computer Science or Statistics\nFamiliarity with major cloud platforms such as AWS and Azure\nHealthcare Industry Experience\n\nMinimum Qualifications:\n\n-Bachelor's Degree\n\nPreferred Qualifications:\n\n- Master’s degree in Computer Science or Statistics\nFamiliarity with major cloud platforms such as AWS and Azure\nHealthcare Industry Experience\n\nWE ARE AN EQUAL OPPORTUNITY EMPLOYER. Applicants and employees are considered for positions and are evaluated without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.\n\nIf you have a disability under the Americans with Disability Act or a similar law, and want a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to careers@Healthfirst.org or calling 212-519-1798 . In your email please include a description of the accommodation you are requesting and a description of the position for which you are applying. Only reasonable accommodation requests related to applying for a position within Healthfirst Management Services will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with Healthfirst Management Services.\nEEO Law Poster and Supplement\n\n]]>","count":1},{"name":"Secure our Nation, Ignite your Future\n\nJoin the top Information Technology and Analytic professionals in the industry to make invaluable contributions to our national security on a daily basis. In this innovative, self-contained, Big Data environment, the ManTech team is responsible for everything from infrastructure, to application development, to data science, to advanced analytics and beyond. The team is diverse, the questions are thought-provoking, and the opportunities for growth and advancement are numerous\n\nThe successful candidate will possess a diverse range of data-focused skills and experience, both technical and analytical. They will have a strong desire and capability for problem solving, data analysis and troubleshooting, analytical thinking, and experimentation.\n\nDuties, Tasks & Responsibilities\nWorking with large, complex, and disparate data sets\nDesigning and implementing innovative ways to analyze and exploit the Sponsors data holdings\nResearching and reporting on a wide variety of Sponsor inquiries\nRaising proactive inquiries to the Sponsor based on observations and proposed data analysis/exploitation\nSolving difficult, non-routine problems by applying advanced analytical methodologies, and improving analytic methodologies\nDeveloping custom searches\nCommunicating and coordinating with internal and external partners as needed\nRequired Experience, Skills, & Technologies\n\nThorough knowledge of appropriate analytic tools and methodologies in one or more of the following:\nApplied mathematics (e.g. probability and statistics, formal modeling, computational social sciences)\nComputer programming (e.g. programming languages, math/statistics packages, computer science, machine learning, scientific computing)\nAbility to code or script in one or more general programming language\nExperience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detection\nKnowledge of relational databases, including SQL and large-scale distributed systems (e.g. Hadoop)\nExpertise with statistical data analysis (e.g. linear models, multivariate analysis, stochastic models, sampling methods)\nDemonstrated effectiveness in collecting information and accurately representing/visualizing it to non-technical third parties\nTS/SCI with Polygraph\nBachelor of Science or equivalent and 12-15 years related experience, but will consider all levels of experience.\nDesired Experience, Skills & Technologies\nPrevious investigative experience using a combination of technical and analytic skills\n#LI-DU1\n\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information.","count":1},{"name":"3 others","count":3}]}},{"name":"Rating","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"2.9","max":"4.2","histogram":[{"bin_start":2.9,"bin_end":3.03,"count":1},{"bin_start":3.03,"bin_end":3.16,"count":1},{"bin_start":3.16,"bin_end":3.29,"count":0},{"bin_start":3.29,"bin_end":3.42,"count":0},{"bin_start":3.42,"bin_end":3.55,"count":1},{"bin_start":3.55,"bin_end":3.68,"count":0},{"bin_start":3.68,"bin_end":3.81,"count":1},{"bin_start":3.81,"bin_end":3.9400000000000004,"count":0},{"bin_start":3.9400000000000004,"bin_end":4.07,"count":0},{"bin_start":4.07,"bin_end":4.2,"count":1}]}},{"name":"Company Name","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"Healthfirst\n3.1","count":1},{"name":"ManTech\n4.2","count":1},{"name":"3 others","count":3}]}},{"name":"Location","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"New York, NY","count":2},{"name":"Chantilly, VA","count":1},{"name":"2 others","count":2}]}},{"name":"Headquarters","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"New York, NY","count":2},{"name":"Herndon, VA","count":1},{"name":"2 others","count":2}]}},{"name":"Size","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"1001 to 5000 employees","count":2},{"name":"5001 to 10000 employees","count":1},{"name":"2 others","count":2}]}},{"name":"Founded","dtype":"int64","stats":{"unique_count":5,"nan_count":0,"min":"1968","max":"2000","histogram":[{"bin_start":1968,"bin_end":1971.2,"count":1},{"bin_start":1971.2,"bin_end":1974.4,"count":0},{"bin_start":1974.4,"bin_end":1977.6,"count":0},{"bin_start":1977.6,"bin_end":1980.8,"count":0},{"bin_start":1980.8,"bin_end":1984,"count":1},{"bin_start":1984,"bin_end":1987.2,"count":0},{"bin_start":1987.2,"bin_end":1990.4,"count":0},{"bin_start":1990.4,"bin_end":1993.6,"count":1},{"bin_start":1993.6,"bin_end":1996.8,"count":0},{"bin_start":1996.8,"bin_end":2000,"count":2}]}},{"name":"Type of ownership","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"Company - Public","count":2},{"name":"Nonprofit Organization","count":1},{"name":"2 others","count":2}]}},{"name":"Industry","dtype":"object","stats":{"unique_count":5,"nan_count":0,"categories":[{"name":"Insurance Carriers","count":1},{"name":"Research & Development","count":1},{"name":"3 others","count":3}]}},{"name":"Sector","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"Business Services","count":3},{"name":"Insurance","count":1},{"name":"Manufacturing","count":1}]}},{"name":"Revenue","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"Unknown / Non-Applicable","count":2},{"name":"$100 to $500 million (USD)","count":2},{"name":"$1 to $2 billion (USD)","count":1}]}},{"name":"Competitors","dtype":"object","stats":{"unique_count":4,"nan_count":0,"categories":[{"name":"-1","count":2},{"name":"EmblemHealth, UnitedHealth Group, Aetna","count":1},{"name":"2 others","count":2}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"index":0,"Job Title":"Sr Data Scientist","Salary Estimate":"$137K-$171K (Glassdoor est.)","Job Description":"Description\n\nThe Senior Data Scientist is responsible for defining, building, and improving statistical models to improve business processes and outcomes in one or more healthcare domains such as Clinical, Enrollment, Claims, and Finance. As part of the broader analytics team, Data Scientist will gather and analyze data to solve and address complex business problems and evaluate scenarios to make predictions on future outcomes and work with the business to communicate and support decision-making. This position requires strong analytical skills and experience in analytic methods including multivariate regressions, hierarchical linear models, regression trees, clustering methods and other complex statistical techniques.\n\nDuties & Responsibilities:\n\n• Develops advanced statistical models to predict, quantify or forecast various operational and performance metrics in multiple healthcare domains\n• Investigates, recommends, and initiates acquisition of new data resources from internal and e…","Rating":3.1,"Company Name":"Healthfirst\n3.1","Location":"New York, NY","Headquarters":"New York, NY","Size":"1001 to 5000 employees","Founded":1993,"Type of ownership":"Nonprofit Organization","Industry":"Insurance Carriers","Sector":"Insurance","Revenue":"Unknown / Non-Applicable","Competitors":"EmblemHealth, UnitedHealth Group, Aetna","_deepnote_index_column":0},{"index":1,"Job Title":"Data Scientist","Salary Estimate":"$137K-$171K (Glassdoor est.)","Job Description":"Secure our Nation, Ignite your Future\n\nJoin the top Information Technology and Analytic professionals in the industry to make invaluable contributions to our national security on a daily basis. In this innovative, self-contained, Big Data environment, the ManTech team is responsible for everything from infrastructure, to application development, to data science, to advanced analytics and beyond. The team is diverse, the questions are thought-provoking, and the opportunities for growth and advancement are numerous\n\nThe successful candidate will possess a diverse range of data-focused skills and experience, both technical and analytical. They will have a strong desire and capability for problem solving, data analysis and troubleshooting, analytical thinking, and experimentation.\n\nDuties, Tasks & Responsibilities\nWorking with large, complex, and disparate data sets\nDesigning and implementing innovative ways to analyze and exploit the Sponsors data holdings\nResearching and reporting on a …","Rating":4.2,"Company Name":"ManTech\n4.2","Location":"Chantilly, VA","Headquarters":"Herndon, VA","Size":"5001 to 10000 employees","Founded":1968,"Type of ownership":"Company - Public","Industry":"Research & Development","Sector":"Business Services","Revenue":"$1 to $2 billion (USD)","Competitors":"-1","_deepnote_index_column":1},{"index":2,"Job Title":"Data Scientist","Salary Estimate":"$137K-$171K (Glassdoor est.)","Job Description":"Overview\n\n\nAnalysis Group is one of the largest international economics consulting firms, with more than 1,000 professionals across 14 offices in North America, Europe, and Asia. Since 1981, we have provided expertise in economics, finance, health care analytics, and strategy to top law firms, Fortune Global 500 companies, and government agencies worldwide. Our internal experts, together with our network of affiliated experts from academia, industry, and government, offer our clients exceptional breadth and depth of expertise.\n\nWe are currently seeking a Data Scientist to join our team. The ideal candidate should be passionate about working on cutting edge research and analytical services for Fortune 500 companies, global pharma/biotech firms and leaders in industries such as finance, energy and life sciences. The Data Scientist will be a contributing member to client engagements and have the opportunity to work with our network of world-class experts and thought leaders.\n\nJob Functio…","Rating":3.8,"Company Name":"Analysis Group\n3.8","Location":"Boston, MA","Headquarters":"Boston, MA","Size":"1001 to 5000 employees","Founded":1981,"Type of ownership":"Private Practice / Firm","Industry":"Consulting","Sector":"Business Services","Revenue":"$100 to $500 million (USD)","Competitors":"-1","_deepnote_index_column":2},{"index":3,"Job Title":"Data Scientist","Salary Estimate":"$137K-$171K (Glassdoor est.)","Job Description":"JOB DESCRIPTION:\n\nDo you have a passion for Data and Machine Learning? Do you dream of working with customers on their most forward-looking AI initiatives? Does the challenge of developing modern machine learning solutions to solve real-world manufacturing problems exciting to you?\n\nWe develop software for monitoring semiconductor manufacturing process and are looking to leverage the latest technologies to address our customer's needs. You will be part of a team that investigates and builds solutions based all the data available in factories, ranging from time series data, to post manufacturing data, to production logs. You will be working side by side with application developers and customers on real world problems with actual manufacturing data.\n\nJOB FUNCTION:\n\nBasic and applied research in statistical machine learning, deep learning, and data science as well as signal and information processing to advance the state of the art in time series analysis of semiconductor manufacturing d…","Rating":3.5,"Company Name":"INFICON\n3.5","Location":"Newton, MA","Headquarters":"Bad Ragaz, Switzerland","Size":"501 to 1000 employees","Founded":2000,"Type of ownership":"Company - Public","Industry":"Electrical & Electronic Manufacturing","Sector":"Manufacturing","Revenue":"$100 to $500 million (USD)","Competitors":"MKS Instruments, Pfeiffer Vacuum, Agilent Technologies","_deepnote_index_column":3},{"index":4,"Job Title":"Data Scientist","Salary Estimate":"$137K-$171K (Glassdoor est.)","Job Description":"Data Scientist\nAffinity Solutions / Marketing Cloud seeks smart, curious, technically savvy candidates to join our cutting-edge data science team. We hire the best and brightest and give them the opportunity to work on industry-leading technologies.\nThe data sciences team at AFS/Marketing Cloud build models, machine learning algorithms that power all our ad-tech/mar-tech products at scale, develop methodology and tools to precisely and effectively measure market campaign effects, and research in-house and public data sources for consumer spend behavior insights. In this role, you'll have the opportunity to come up with new ideas and solutions that will lead to improvement of our ability to target the right audience, derive insights and provide better measurement methodology for marketing campaigns. You'll access our core data asset and machine learning infrastructure to power your ideas.\nDuties and Responsibilities\n· Support all clients model building needs, including maintaining and …","Rating":2.9,"Company Name":"Affinity Solutions\n2.9","Location":"New York, NY","Headquarters":"New York, NY","Size":"51 to 200 employees","Founded":1998,"Type of ownership":"Company - Private","Industry":"Advertising & Marketing","Sector":"Business Services","Revenue":"Unknown / Non-Applicable","Competitors":"Commerce Signals, Cardlytics, Yodlee","_deepnote_index_column":4}]},"text/plain":"   index          Job Title               Salary Estimate  \\\n0      0  Sr Data Scientist  $137K-$171K (Glassdoor est.)   \n1      1     Data Scientist  $137K-$171K (Glassdoor est.)   \n2      2     Data Scientist  $137K-$171K (Glassdoor est.)   \n3      3     Data Scientist  $137K-$171K (Glassdoor est.)   \n4      4     Data Scientist  $137K-$171K (Glassdoor est.)   \n\n                                     Job Description  Rating  \\\n0  Description\\n\\nThe Senior Data Scientist is re...     3.1   \n1  Secure our Nation, Ignite your Future\\n\\nJoin ...     4.2   \n2  Overview\\n\\n\\nAnalysis Group is one of the lar...     3.8   \n3  JOB DESCRIPTION:\\n\\nDo you have a passion for ...     3.5   \n4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n\n              Company Name       Location            Headquarters  \\\n0         Healthfirst\\n3.1   New York, NY            New York, NY   \n1             ManTech\\n4.2  Chantilly, VA             Herndon, VA   \n2      Analysis Group\\n3.8     Boston, MA              Boston, MA   \n3             INFICON\\n3.5     Newton, MA  Bad Ragaz, Switzerland   \n4  Affinity Solutions\\n2.9   New York, NY            New York, NY   \n\n                      Size  Founded        Type of ownership  \\\n0   1001 to 5000 employees     1993   Nonprofit Organization   \n1  5001 to 10000 employees     1968         Company - Public   \n2   1001 to 5000 employees     1981  Private Practice / Firm   \n3    501 to 1000 employees     2000         Company - Public   \n4      51 to 200 employees     1998        Company - Private   \n\n                                Industry             Sector  \\\n0                     Insurance Carriers          Insurance   \n1                 Research & Development  Business Services   \n2                             Consulting  Business Services   \n3  Electrical & Electronic Manufacturing      Manufacturing   \n4                Advertising & Marketing  Business Services   \n\n                      Revenue  \\\n0    Unknown / Non-Applicable   \n1      $1 to $2 billion (USD)   \n2  $100 to $500 million (USD)   \n3  $100 to $500 million (USD)   \n4    Unknown / Non-Applicable   \n\n                                         Competitors  \n0            EmblemHealth, UnitedHealth Group, Aetna  \n1                                                 -1  \n2                                                 -1  \n3  MKS Instruments, Pfeiffer Vacuum, Agilent Tech...  \n4               Commerce Signals, Cardlytics, Yodlee  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Job Title</th>\n      <th>Salary Estimate</th>\n      <th>Job Description</th>\n      <th>Rating</th>\n      <th>Company Name</th>\n      <th>Location</th>\n      <th>Headquarters</th>\n      <th>Size</th>\n      <th>Founded</th>\n      <th>Type of ownership</th>\n      <th>Industry</th>\n      <th>Sector</th>\n      <th>Revenue</th>\n      <th>Competitors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Sr Data Scientist</td>\n      <td>$137K-$171K (Glassdoor est.)</td>\n      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n      <td>3.1</td>\n      <td>Healthfirst\\n3.1</td>\n      <td>New York, NY</td>\n      <td>New York, NY</td>\n      <td>1001 to 5000 employees</td>\n      <td>1993</td>\n      <td>Nonprofit Organization</td>\n      <td>Insurance Carriers</td>\n      <td>Insurance</td>\n      <td>Unknown / Non-Applicable</td>\n      <td>EmblemHealth, UnitedHealth Group, Aetna</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Data Scientist</td>\n      <td>$137K-$171K (Glassdoor est.)</td>\n      <td>Secure our Nation, Ignite your Future\\n\\nJoin ...</td>\n      <td>4.2</td>\n      <td>ManTech\\n4.2</td>\n      <td>Chantilly, VA</td>\n      <td>Herndon, VA</td>\n      <td>5001 to 10000 employees</td>\n      <td>1968</td>\n      <td>Company - Public</td>\n      <td>Research &amp; Development</td>\n      <td>Business Services</td>\n      <td>$1 to $2 billion (USD)</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Data Scientist</td>\n      <td>$137K-$171K (Glassdoor est.)</td>\n      <td>Overview\\n\\n\\nAnalysis Group is one of the lar...</td>\n      <td>3.8</td>\n      <td>Analysis Group\\n3.8</td>\n      <td>Boston, MA</td>\n      <td>Boston, MA</td>\n      <td>1001 to 5000 employees</td>\n      <td>1981</td>\n      <td>Private Practice / Firm</td>\n      <td>Consulting</td>\n      <td>Business Services</td>\n      <td>$100 to $500 million (USD)</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Data Scientist</td>\n      <td>$137K-$171K (Glassdoor est.)</td>\n      <td>JOB DESCRIPTION:\\n\\nDo you have a passion for ...</td>\n      <td>3.5</td>\n      <td>INFICON\\n3.5</td>\n      <td>Newton, MA</td>\n      <td>Bad Ragaz, Switzerland</td>\n      <td>501 to 1000 employees</td>\n      <td>2000</td>\n      <td>Company - Public</td>\n      <td>Electrical &amp; Electronic Manufacturing</td>\n      <td>Manufacturing</td>\n      <td>$100 to $500 million (USD)</td>\n      <td>MKS Instruments, Pfeiffer Vacuum, Agilent Tech...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Data Scientist</td>\n      <td>$137K-$171K (Glassdoor est.)</td>\n      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n      <td>2.9</td>\n      <td>Affinity Solutions\\n2.9</td>\n      <td>New York, NY</td>\n      <td>New York, NY</td>\n      <td>51 to 200 employees</td>\n      <td>1998</td>\n      <td>Company - Private</td>\n      <td>Advertising &amp; Marketing</td>\n      <td>Business Services</td>\n      <td>Unknown / Non-Applicable</td>\n      <td>Commerce Signals, Cardlytics, Yodlee</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5493f0ce29fe4401aab16b1879331e75","deepnote_cell_type":"text-cell-h1"},"source":"# Drop the 'index' Column","block_group":"287ca0075bd241bdbf796def440c685f"},{"cell_type":"code","metadata":{"source_hash":"71c4b67c","execution_start":1698280322077,"execution_millis":113,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":2},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"5b171941c9944c7994a5e45639b2586b","deepnote_cell_type":"code"},"source":"df.drop(columns=['index'], inplace=True)","block_group":"42281d0684854b98bc7100ea471445b7","execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d6c16484f3f146c594c184c2eb89de45","deepnote_cell_type":"text-cell-p"},"source":"The index column seems redundant since we already have a default index in the DataFrame. We might consider dropping it.\n","block_group":"f37461ffb99846069de9ac90e7bd1c2e"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"199d6108ae2242409c12034a1c142aa9","deepnote_cell_type":"text-cell-h1"},"source":"# The sum of missing values for each column","block_group":"61b96f92b339444f9d0489f389970ebf"},{"cell_type":"code","metadata":{"source_hash":"e345d44","execution_start":1698280322135,"execution_millis":19,"deepnote_to_be_reexecuted":false,"cell_id":"9c3f3f7f7bf245d3a96093dd0cca33f3","deepnote_cell_type":"code"},"source":"df.isnull().sum()\ndf.info()","block_group":"174aa5891ba545e7ad8b96a344b47b8e","execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 672 entries, 0 to 671\nData columns (total 14 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Job Title          672 non-null    object \n 1   Salary Estimate    672 non-null    object \n 2   Job Description    672 non-null    object \n 3   Rating             672 non-null    float64\n 4   Company Name       672 non-null    object \n 5   Location           672 non-null    object \n 6   Headquarters       672 non-null    object \n 7   Size               672 non-null    object \n 8   Founded            672 non-null    int64  \n 9   Type of ownership  672 non-null    object \n 10  Industry           672 non-null    object \n 11  Sector             672 non-null    object \n 12  Revenue            672 non-null    object \n 13  Competitors        672 non-null    object \ndtypes: float64(1), int64(1), object(12)\nmemory usage: 73.6+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"941715cfee294df0a2dcaec7968047fb","deepnote_cell_type":"text-cell-p"},"source":"The line df.isnull().sum() is used to identify the number of missing values in each column of the DataFrame. By running this line, I can quickly see which columns have missing data. This step is crucial in data cleaning because missing values can skew analysis and modeling results, and it's essential to decide how to handle them. On the other hand, the line df.info() provides a concise summary of the DataFrame, including the data types of each column, the number of non-null values, the index type, and the memory usage. This information is vital during the data cleaning phase because it helps me understand the structure of the dataset and the types of data it contains. It can also give me insights into the overall quality of the data and whether any data types need to be adjusted for further analysis.","block_group":"20f067bbd13342c3a1408d38b120ee61"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7f5668fdebc24ea6bcc23f5214bb52ed","deepnote_cell_type":"text-cell-h1"},"source":"# Replacing -1 with NaN for columns containing -1","block_group":"bfbb7538fe284b50851b4acd1a801645"},{"cell_type":"code","metadata":{"source_hash":"bbe3c6e5","execution_start":1698280322136,"execution_millis":76,"deepnote_to_be_reexecuted":false,"cell_id":"9844fa24137d495e85960e8bc1fdb555","deepnote_cell_type":"code"},"source":"df.replace(['-1'], [np.NaN], inplace=True)\ndf.replace(['-1.0'], [np.NaN], inplace=True)\ndf.replace([-1], [np.NaN], inplace=True)\ndf.isnull().sum()","block_group":"48fdaf99aec24f2eb7e33106e62ff22d","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"Job Title              0\nSalary Estimate        0\nJob Description        0\nRating                50\nCompany Name           0\nLocation               0\nHeadquarters          31\nSize                  27\nFounded              118\nType of ownership     27\nIndustry              71\nSector                71\nRevenue               27\nCompetitors          501\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"faa80d7489af421583fd564355827d28","deepnote_cell_type":"text-cell-p"},"source":"The Competitors column contains a value of -1 for rows without any competitors. We might consider replacing -1 with NaN or another placeholder to represent missing values. Same with the Rating column. Because the Competitor column contains so many null values now er might consider dropping it. However, it depends on the user and what they need.","block_group":"b4b63c5d244941b5ac98a0a316fcb096"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a5f292d1c41b4d14b73bf350b8514565","deepnote_cell_type":"text-cell-h1"},"source":"# Split 'Salary Estimate' into 'Minimum Salary' and 'Maximum Salary' and convert to numeric","block_group":"bbe4341f8138420d91db985a67c8ad65"},{"cell_type":"code","metadata":{"source_hash":"6c63f204","execution_start":1698280322231,"execution_millis":15,"deepnote_to_be_reexecuted":false,"cell_id":"9297216acd2744c5949d7427354b6dfd","deepnote_cell_type":"code"},"source":"df['Minimum Salary'] = df['Salary Estimate'].str.split('-').str[0].str.extract('(\\d+)').astype(float) * 1000  # Multiplied by 1000 to convert 'K' to actual values\ndf['Maximum Salary'] = df['Salary Estimate'].str.split('-').str[1].str.extract('(\\d+)').astype(float) * 1000  # Multiplied by 1000 to convert 'K' to actual values\n# Drop the original column\ndf.drop(columns=['Salary Estimate'], inplace=True)  \n","block_group":"6c332dd919d845ccb4156cca4984c954","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5724e48a9335494ea6c99e7a38d4a609","deepnote_cell_type":"text-cell-p"},"source":"The Salary Estimate column contains a range and additional text (\"Glassdoor est.\"). To extract the minimum salary from the 'Salary Estimate' column in the DataFrame df, I used the str.split method to split the values by the '-' symbol and then selected the first part. After that, I used the str.extract method with the regular expression (\\d+) to extract the numerical part. To convert the 'K' values to their actual numerical values, I multiplied the extracted values by 1000 and assigned them to a new column named 'Minimum Salary'. Similarly, I extracted the maximum salary using the same approach and assigned it to a new column named 'Maximum Salary'. Finally, I dropped the original 'Salary Estimate' column using the drop method with the argument columns=['Salary Estimate'] and setting inplace=True to apply the changes directly to the DataFrame.","block_group":"4bd0fe8a84854aa6b177d2285542de17"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9b94293771844db6981f20f8941e718b","deepnote_cell_type":"text-cell-h1"},"source":"# Clean 'Company Name' to remove the rating","block_group":"6867c78bc2474e5fa1b16be4035198cc"},{"cell_type":"code","metadata":{"source_hash":"20404667","execution_start":1698280322231,"execution_millis":51,"deepnote_to_be_reexecuted":false,"cell_id":"dc4ff5c29dda4c1d9f7f5e9753194ae1","deepnote_cell_type":"code"},"source":"df['Company Name'] = df['Company Name'].str.split('\\n').str[0]","block_group":"9d5ee6134a284406bd30d3647a514466","execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"bb70a58822114fa699287e0c7db277e4","deepnote_cell_type":"text-cell-p"},"source":"The Company Name column contains both the company name and its rating. The rating is redundant here since we already have a Rating column. We should clean this column to only contain the company name.To clean up the 'Company Name' column in my DataFrame, I used the str.split('\\n').str[0] method. This method splits the strings in the 'Company Name' column on the newline character (\\n) and retains only the first part of the split strings. The resulting values were then assigned back to the 'Company Name' column.","block_group":"215678d42c3147f8bf860ff1a378d35b"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"27c8099ff21744a9a6b0dd6259e28c34","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"b700f3c2fcce4ee590dc776605c63e2a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8eb1984193bb47bb8bd36adeaac6204f","deepnote_cell_type":"text-cell-h1"},"source":"# Making city and state columns for both Location and Headquarters","block_group":"cd32fea71a2b41ca89c3033e9d96eb99"},{"cell_type":"code","metadata":{"source_hash":"184b383a","execution_start":1698280322275,"execution_millis":11,"deepnote_to_be_reexecuted":false,"cell_id":"704a53fa5194418093357022bd3a669a","deepnote_cell_type":"code"},"source":"Location = df['Location'].str.split(\",\",expand=True,)\nLocation_City = Location[0]\nLocation_State = Location[1]\ndf['Location City'] = Location_City\ndf['Location State'] = Location_State\ndf.drop('Location',axis = 1, inplace = True)\n\nHQ = df['Headquarters'].str.split(\",\",expand=True)\nHeadquarters_City = HQ[0]\nHeadquarters_State = HQ[1]\ndf['Headquarters City'] = Headquarters_City\ndf['Headquarters State'] = Headquarters_State\ndf.drop('Headquarters',axis = 1, inplace = True)","block_group":"d3f9eb08a36e490ebcabd43670ed79af","execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4bbc728e7bce4a3990109a2ebabaf624","deepnote_cell_type":"text-cell-p"},"source":"First, I utilized the str.split() method in Pandas to split the 'Location' column into two separate columns, 'Location City' and 'Location State', using a comma as the delimiter. This allowed me to separate the city and state information that was previously combined in a single column. By setting expand=True, I ensured that the split elements were returned as different columns. After the split, I assigned the first part to 'Location City' and the second part to 'Location State' in the data frame. Following this, to streamline the DataFrame further, I repeated the process for the 'Headquarters' column. I split it into two separate columns, 'Headquarters City' and 'Headquarters State', using a comma as the delimiter. Similar to the previous step, I set expand=True to ensure that the split elements are returned as different columns. Then, I assigned the first part to 'Headquarters City' and the second part to 'Headquarters State' in the DataFrame. Finally, to clean up the DataFrame, I dropped the original 'Location' and 'Headquarters' columns using the drop() function, specifying the 'axis' parameter as 1 to indicate that the operation should be performed on columns.","block_group":"b59f46553b3d40c5aeb9bf41207dd748"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"83a5de0eaf154fa8a996dff83c87d66b","deepnote_cell_type":"text-cell-h1"},"source":"# Cleaning the Revenue column","block_group":"423efd129db64254acac9ae93f986714"},{"cell_type":"code","metadata":{"source_hash":"1db31066","execution_start":1698280322391,"execution_millis":9,"deepnote_to_be_reexecuted":false,"cell_id":"d08d428bca8c4dbbba01f6fa5fcb70c9","deepnote_cell_type":"code"},"source":"df['Revenue'] = df['Revenue'].replace('Unknown / Non-Applicable', np.NaN)\n# data['Revenue']=data['Revenue'].replace('Unknown / Non-Applicable', np.nan)\ndf['Revenue'] = df['Revenue'].replace('Unknown/Non-Applicable', np.nan)\nRevenue = df['Revenue'].str.split(\"to\",expand=True)","block_group":"8bc9bb2276a240339aafded37ab23d2b","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2d8ad541c4264f88bf269303f3ab3945","deepnote_cell_type":"text-cell-p"},"source":"First, I needed to handle the missing data in the 'Revenue' column. I replaced the string 'Unknown / Non-Applicable' with NaN (Not a Number), which is a standard way to represent missing or null values in Python. To achieve this, I used the code df['Revenue'] = df['Revenue'].replace('Unknown / Non-Applicable', np.NaN).","block_group":"58076913d821417e9d29310d3e06c17f"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"1363e109b50048c3a7638391fdf02f33","deepnote_cell_type":"text-cell-p"},"source":"Later, I realized that there might be a variation of the string, so I used an additional line of code df['Revenue'] = df['Revenue'].replace('Unknown/Non-Applicable', np.nan) to account for cases where the string was 'Unknown/Non-Applicable'. This ensured that all variations of the string were replaced with NaN.","block_group":"8382f6c2733e4699ba4f8c3faf701ef4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"ab355db788d4464ab52534efe2acd961","deepnote_cell_type":"text-cell-p"},"source":"Furthermore, I noticed that the 'Revenue' column had some entries in the format 'X to Y', and I wanted to split these into two separate columns. To do this, I used the str.split method along with expand=True to split the 'Revenue' column into two columns, which I named 'Revenue_1' and 'Revenue_2'. This helped me create a more structured and usable dataset for further analysis.","block_group":"2a979e5654d440b2bf80cd8e139a45c0"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"990e37d6d3c24f6994d3e2c0ef2a38c6","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"53cdd4e32fb9403a9b070e017c3d6e8b"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"cc6b20c07db64e71ac42e1df6505ad8e","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"07ac449e88da4c459dc2602f07c4f2c4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"352e18cba0e74c4b8fa3e555ecab27c7","deepnote_cell_type":"text-cell-h1"},"source":"# Summary of Data Cleaning","block_group":"7256d8b378d14ae2a6535bd68b04fe04"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a23de576cfef46fbad27a2307565b743","deepnote_cell_type":"text-cell-p"},"source":"Dropping the 'index' column: I noticed that the 'index' column was redundant since the DataFrame already had a default index. I dropped this column to streamline the dataset.","block_group":"b67c063e4a174445b95f78060f09f224"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4c8a02317abf436ba158d7b9593ce964","deepnote_cell_type":"text-cell-p"},"source":"Identifying missing values: I used the isnull().sum() function to determine the number of missing values in each column. Understanding the extent of missing data is crucial for determining the appropriate data-cleaning strategy.","block_group":"f47bf57769f34c8db128c53839e7b662"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d2e9b4e43eed49f4aa7ae6b41a19bc3d","deepnote_cell_type":"text-cell-p"},"source":"Replacing -1 with NaN: In columns where the value of -1 represented missing data, I replaced -1 with NaN. This step was essential for preparing the data for further analysis.","block_group":"4f17b29672dc4a71afbcb85d22cf40d7"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0efa3578266c4d9099646792e73b81bd","deepnote_cell_type":"text-cell-p"},"source":"Splitting 'Salary Estimate' into 'Minimum Salary' and 'Maximum Salary': I split the 'Salary Estimate' column to extract the minimum and maximum salary values. I converted the extracted values to numeric form for easier analysis.","block_group":"86d07f984b90451381fc860921ce702d"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"20e9ab2872fe42d6a452ae37afb6e9c8","deepnote_cell_type":"text-cell-p"},"source":"Cleaning the 'Company Name' column: I removed the rating from the 'Company Name' column to keep only the company names, making the data more readable and easier to work with.","block_group":"1e93b7966ca54c54864ec8bd815b8da4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9052c37ebc434bd083f37ad92a8b7c24","deepnote_cell_type":"text-cell-p"},"source":"Creating city and state columns for 'Location' and 'Headquarters': I split the 'Location' and 'Headquarters' columns into 'City' and 'State' columns to separate the city and state information, making it easier to analyze and visualize geographical data.","block_group":"6ffe81a2c9494223ac06ac50ac14b91e"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d5a3550efed64de6b412c5713ac06910","deepnote_cell_type":"text-cell-p"},"source":"Cleaning the 'Revenue' column: I identified and replaced various forms of the 'Unknown / Non-Applicable' string in the 'Revenue' column with NaN to handle missing data appropriately. Additionally, I split the 'Revenue' column into separate columns to create a more structured dataset.","block_group":"43b8e7ad299e41d0bdf37d67cde251dd"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"26582b3e60604597ac36770518032a9b","deepnote_cell_type":"text-cell-p"},"source":"By performing these data-cleaning operations, I aimed to create a more organized and usable dataset for further analysis and modeling.","block_group":"9eb2067bbde54bef820cda473b647a4d"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"dde5ce12df4b4346b24fc9d518892e3b","deepnote_cell_type":"text-cell-p"},"source":"I used ChatGPT to generate this summary.","block_group":"8b7d2116e03b4720b7a53fdcff7d2708"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a000e2dadc984db4acc120fb59e71feb","deepnote_cell_type":"text-cell-p"},"source":"Citation:","block_group":"73ca1f70f720453ba28b94319f807f98"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"6467162ee5bd47e6b3bf098667ff8c5b","deepnote_cell_type":"text-cell-p"},"source":"OpenAI. (2023). ChatGPT (September 25 Version) [Large language model]. https://chat.openai.com","block_group":"f493d563a9b94787b3646d2f15fbc18d"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c5846eb3c7f54a18b428ce3127d208de","deepnote_cell_type":"text-cell-p"},"source":"","block_group":"bf8b7c42a7a8407e8a269ca3d902f3f0"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=23bf5da6-7a5d-45f0-933e-b77d36ae4577' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"3126da8d0fdf4a799656fe5587425414","deepnote_persisted_session":{"createdAt":"2023-10-14T18:16:29.137Z"},"deepnote_execution_queue":[]}}